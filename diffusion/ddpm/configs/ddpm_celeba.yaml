config:
  project_name: ddpm
  log_to: tensorboard
  log_dir: logs/ddpm_celeba_logs
  device: cuda:1
  
  eval_freq: 1000
  checkpoint_freq: 1000
  model_checkpoint: null
  optim_checkpoint: null

data:
  dataset: celeba
  data_root: data/celeba_hq_256
  img_size: 112
  img_channels: 3
  log_to: tensorboard

training:
  lr: 0.0002
  batch_size: 32
  iterations: 800000
    
sampling:
  sampling_method: ddpm
  num_samples: 16
  n_rows: 4
  model_path: logs/ddpm_celeba_logs/ddpm-ddpm-2024-01-02-14-43-iteration-54000-model.pth
  save_dir: sample_images

diffusion: 
  base_channels: 128
  channel_mults: [1, 2, 2, 2]
  num_res_blocks: 2
  time_emb_dim: 512
  norm: gn
  dropout: 0.1
  activation: silu
  attention_resolutions: [1, ]
  schedule: linear
  num_timesteps: 1000
  schedule_low: 0.0001
  schedule_high: 0.02
  use_labels: false
  ema_decay: 0.9999
  ema_update_rate: 1
  loss_type: l2
  