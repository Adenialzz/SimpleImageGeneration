# -*- coding: utf-8 -*-

"""
Created on January 28, 2021

@author: Siqi Miao
"""

import os
from tqdm import tqdm
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import torch
from torchvision import transforms
from torchvision.utils import save_image
from torchvision.datasets import MNIST

import argparse

from models import CVAE
from losses import vae_loss


def parse_cfg():
    parser = argparse.ArgumentParser()
    parser.add_argument('--device', type=str, default='cuda:0')
    parser.add_argument('--batch_size', type=int, default=1024)
    parser.add_argument('--dataset_path', type=str, default='./data')
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--x_dim', type=int, default=784)
    parser.add_argument('--hidden_dim', type=int, default=400)
    parser.add_argument('--latent_dim', type=int, default=200)

    cfg = parser.parse_args()
    return cfg

def main(cfg):

    latent_size = 64
    in_features = 28 * 28

    data = MNIST('./data', download=True, transform=transforms.ToTensor())
    data_loader = torch.utils.data.DataLoader(data, batch_size=cfg.batch_size, shuffle=True)

    # train VCAE
    model = CVAE(in_features, latent_size, y_size=1).to(cfg.device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr)

    print('Start Training CVAE...')
    for epoch in range(1, 1 + cfg.epochs):

        model.train()

        total_loss = 0
        pbar = tqdm(data_loader)
        for X, y in pbar:
            batch_size = X.shape[0]
            X = X.view(batch_size, -1).to(cfg.device)
            y = y.to(cfg.device)
            model.zero_grad()

            mu_prime, mu, log_var = model(X, y)

            loss = vae_loss(X.view(batch_size, -1), mu_prime, mu, log_var)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            pbar.set_description('Loss: {loss:.4f}'.format(loss=loss.item()))

        print(f"Epochs: {epoch}, AvgLoss: {total_loss/len(data_loader):.4f}")
    print('Training for CVAE has been done.')


    model.eval()
    with torch.no_grad():
        num_classes = len(data.classes)

        # sample generated by CVAE
        z = torch.randn(num_classes ** 2, latent_size).to(cfg.device)
        y = torch.arange(num_classes).repeat(num_classes).to(cfg.device)
        z_given_Y = torch.cat((z, y.unsqueeze(1)), dim=1)
        out = model.decoder(z_given_Y)
        save_image(out.view(-1, 1, 28, 28), 'generated_samples.jpg', nrow=num_classes)


if __name__ == '__main__':
    cfg = parse_cfg()
    main(cfg)
